<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1"/>
  <link href="https://fonts.googleapis.com/css2?family=Russo+One&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@500&family=Russo+One&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="default.css">
  <link rel="stylesheet" href="menudropdown.css">
  <link id="theme-style" rel="stylesheet" href="">
  <title>veille technologique</title>
</head>
<body>
  <section class="s1">
    <div class='main-container'>

      <div class="greeting-wrapper">
        <h1>Veille technologique</h1>
      </div>

      <div class="intro-wrapper">
            
            <div class="nav-wrapper">
              <div class="dots-wrapper">
                <div id="dot-1" class='browser-dot'></div>
                <div id="dot-2" class='browser-dot'></div>
                <div id="dot-3" class='browser-dot'></div>
              </div>
              <ul id="navigation">
                <li>
                  <a href="Bts_sio.html">Accueil</a>
                </li>
                <li>
                  <div class="dropdown">
                    <span class="dropbtn"><a>E4</a></span>
                    <div class="dropdown-content">
                      <a href="projet_web.html">Projet web</a>
                      <a href="projet_appli.html">Projet Appli C#</a>
                    </div>
                  </div>
                </li>
                <li>
                  <div class="dropdown">
                    <span class="dropbtn"><a>E6</a></span>
                    <div class="dropdown-content">
                      <a href="tableau_de_synthese.html">Tableau de Synthèse</a>
                      <a href="veille.html">Veille technologique</a>
                      <a href="situation.html">Situation professionnelle</a>
                    </div>
                  </div>
                </li>
              </ul>
            </div>


           
            
      </div>

    </div>
    <div>
      <div class="post">
       
        <div class="post-preview">
         <h5 class="post-tittle">Le Big Data </h5>
         <h6 class="post-tittle">Définition</h6>
         <p class="post-intro">
            <p>
               Le big data ( « grosses données » en anglais), les mégadonnées ou les données massives, désigne les ressources d’informations dont les caractéristiques en termes de volume, de vélocité et de variété imposent l’utilisation de technologies et de méthodes analytiques particulières pour générer de la valeur, et qui dépassent en général les capacités d'une seule et unique machine et nécessitent des traitements parallélisés.
            </p>
            <p>
            L’explosion quantitative (et souvent redondante) des données numériques permet une nouvelle approche pour analyser le monde. Le volume colossal de données numériques disponibles, implique de mettre en œuvre de nouveaux ordres de grandeur concernant la capture, le stockage, la recherche, le partage, l'analyse et la visualisation des données. Le traitement des big data permet de nouvelles possibilités d'exploration de l'information et des données, celles-ci proviennent de nombreuses sources numériques : les réseaux sociaux, les médias, l'Open Data, le Web, des bases de données privées, publiques à caractère commercial ou scientifique. Cela permet des recoupements et des analyses prédictives dans de nombreux domaines : scientifique, santé, économique, commercial... La multiplicité des applications a été comprise et développée par les plus gros acteurs du secteur des technologies de l'information.
            </p>
            <p>
            Divers experts, grandes institutions (comme le MIT aux États-Unis, le Collège de France en Europe), administrations et spécialistes sur le terrain des technologies ou des usages considèrent le phénomène big data comme l'un des grands défis informatiques de la décennie 2010-2020 et en ont fait une de leurs nouvelles priorités de recherche et développement, qui pourrait notamment conduire à l'Intelligence artificielle en étant exploré par des réseaux de neurones artificiels autoapprenants.
             </p>

         </p>
        </div>
      </div>

      <div class="post">
         <div class="post-preview">
         <h6 class="post-tittle">Histoire</h6>
         <p class="post-intro">
            <p>Le big data a une histoire récente et pour partie cachée, en tant qu'outil des technologies de l'information et comme espace virtuel prenant une importance volumique croissante dans le cyberespace. </p>
            <p>
            L'expression « big data » serait apparue en octobre 1997 selon les archives de la bibliothèque numérique de l'Association for Computing Machinery (ACM), dans un article scientifique sur les défis technologiques à relever pour visualiser les « grands ensembles de données ».
            </p>
            <p>
            La naissance du Big Data est liée aux progrès des capacités des systèmes de stockage, de fouille et d'analyse de l'information numérique, qui ont vécu une sorte de big bang des données. Mais ses prémices sont à trouver dans le croisement de la cybernétique et de courants de pensée nés durant la Seconde Guerre mondiale, selon lesquels l’homme et le monde peuvent être représentés comme « des ensembles informationnels, dont la seule différence avec la machine est leur niveau de complexité. La vie deviendrait alors une suite de 0 et de 1, programmable et prédictible ».
            </p>
            <p>
            Les évolutions qui caractérisent le big data et ses algorithmes, ainsi que celles de la science des données sont en partie cachées (au sein des services de renseignement des grands États) et si rapides et potentiellement profondes que peu de prospectivistes se risquent à pronostiquer son devenir à moyen ou long terme, mais la plupart des observateurs y voient des enjeux majeurs pour l'avenir, tant en termes d'opportunités commerciales que de bouleversements sociopolitiques et militaires, avec en particulier le risque de voir émerger des systèmes ubiquistes, orwelliens et totalitaires capables de fortement contrôler, surveiller et/ou influencer les individus et groupes.
            </p>
            <p>
            Les risques de dérives de la part de gouvernements ou d'entreprises ont surtout d'abord été décrits par Orwell à la fin de la dernière guerre mondiale, puis souvent par la science fiction. Avec l'apparition de grandes banques de données dans les années 1970 (et durant toute la période de la guerre froide) de nombreux auteurs s'inquiètent des risques pris concernant la protection de la vie privée, en particulier Arthur R. Miller (en) qui cite l'exemple de la croissance des données stockées relatives à la santé physique et psychique des individus.
            </p>
            <p>
            En 2000, Froomkin, dans un article paru dans la revue Stanford Law Review, se demande si la vie privée n'est pas déjà morte, mais ce sont surtout les révélations d'Edward Snowden (2013) qui ont suscité une nouvelle prise de conscience et d'importants mouvements de protestation citoyenne.
            </p>
            <p>
            Les quatre droits et « états de base de la vie privée » tels qu'énoncés par Westin en 1962 (droit à la solitude, à l'intimité, à l'anonymat dans la foule et à la réserve) sont menacés dans un nombre croissant de situations, de même que la protection du contenu des courriers électroniques qui fait partie du droit à la vie privée.
            </p>
         </p>
      </div>
      </div>

      <div class="post">
         <div class="post-preview">
         <h6 class="post-tittle">Dimensions</h6>
         <p class="post-intro">
            <p>
               Le big data s'accompagne du développement d'applications à visée analytique, qui traitent les données pour en tirer du sens. Ces analyses sont appelées big analytics ou « broyage de données ». Elles portent sur des données quantitatives complexes à l'aide de méthodes de calcul distribué et de statistiques.
               </p>
               <p>
               En 2001, un rapport de recherche du META Group (devenu Gartner)  définit les enjeux inhérents à la croissance des données comme étant tri-dimensionnels : les analyses complexes répondent en effet à la règle dite « des 3V » (volume, vélocité et variété). Ce modèle est encore largement utilisé aujourd’hui pour décrire ce phénomène. Aux 3 V initiaux, sont parfois ajoutés d'autres V comme: Véracité, Valeur et Visualisation.
               </p>
               
         </p>
         <div class="post-preview">
            <h6 class="post-tittle">Volume</h6>
            <p class="post-intro">
               <p>
                  Le big data s'accompagne du développement d'applications à visée analytique, qui traitent les données pour en tirer du sens. Ces analyses sont appelées big analytics ou « broyage de données ». Elles portent sur des données quantitatives complexes à l'aide de méthodes de calcul distribué et de statistiques.
                  </p>
                  <p>
                  En 2001, un rapport de recherche du META Group (devenu Gartner)  définit les enjeux inhérents à la croissance des données comme étant tri-dimensionnels : les analyses complexes répondent en effet à la règle dite « des 3V » (volume, vélocité et variété). Ce modèle est encore largement utilisé aujourd’hui pour décrire ce phénomène. Aux 3 V initiaux, sont parfois ajoutés d'autres V comme: Véracité, Valeur et Visualisation.
                  </p>
                  
            </p>
         </div>

         <div class="post-preview">
            <h6 class="post-tittle">Variété</h6>
            <p class="post-intro">
               <p>
                  Le volume des big data met les centres de données face à un réel défi : la variété des données. Il ne s'agit pas uniquement de données relationnelles traditionnelles, mais surtout de données brutes, semi-structurées, voire non structurées (cependant, les données non structurées devront être analysée et structurées ultérieurement si nécessaire pour leur utilisation48). Ce sont des données complexes proviennent de multiples sources: du web (Web mining), de bases publiques (open data, Web des données), géo-démographiques par îlot (adresses IP), machines ou objets connectés (IoT), ou relever de la propriété des entreprises et des consommateurs[réf. nécessaire]. Ce qui les rend inaccessibles aux outils traditionnels.
                  </p>
                  <p>
                  La démultiplication des outils de collecte sur les individus et sur les objets permet d’amasser toujours plus de données49. Et les analyses sont d’autant plus complexes qu’elles portent de plus en plus sur les liens entre des données de natures différentes.
                  </p>
                  
                  
            </p>
         </div>

         <div class="post-preview">
            <h6 class="post-tittle">Vélocité</h6>
            <p class="post-intro">
                  <p>
                  La vélocité représente la fréquence à laquelle les données sont à la fois générées, capturées, partagées et mises à jour.
                  </p>
                  <p>
                  Des flux croissants de données doivent être analysés en quasi-temps réel (fouille de flots de données) pour répondre aux besoins des processus chrono-sensibles. Par exemple, les systèmes mis en place par la bourse et les entreprises doivent être capables de traiter ces données avant qu’un nouveau cycle de génération n’ait commencé, avec le risque pour l'Homme de perdre une grande partie de la maîtrise du système quand les principaux opérateurs deviennent des machines capables de lancer des ordres d'achat ou de vente à la nanoseconde (trading haute fréquence) sans disposer de tous les critères pertinents d'analyse pour le moyen et long terme.
                  </p>     
            </p>
         </div>

         <div class="post-preview">
            <h6 class="post-tittle">Véracité</h6>
            <p class="post-intro">
                  <p>
                  La véracité fait référence à la fiabilité et à la dimension qualitative des données. Traiter et gérer l’incertitude et les erreurs rencontrées dans certaines données, représente un challenge de taille pour fiabiliser et minimiser les biais.
                  </p>
            </p>
         </div>

         <div class="post-preview">
            <h6 class="post-tittle">Valeur</h6>
            <p class="post-intro">
                  <p>
                     Les efforts et les investissements dans l'utilisation et application Big Data n’ont de sens que si elles apportent de la valeur ajoutée.
                  </p>
            </p>
         </div>

         <div class="post-preview">
            <h6 class="post-tittle">Visualisation</h6>
            <p class="post-intro">
                  <p>
                  La mise en forme et mise à disposition des données et des résultats de l'analyse des données, permet de faciliter sa compréhension et son interprétation, afin d'améliorer la prise de décisions.
                  </p>
                  
            </p>
         </div>

         <div class="post-preview">
            <h6 class="post-tittle">Différence avec l'informatique décisionnelle</h6>
            <p class="post-intro">
                  <p>
                  Si la définition du Gartner en 3V est encore largement reprise (voire augmentée de “V” supplémentaires selon l’inspiration des services marketing), la maturation du sujet fait apparaître un autre critère plus fondamental de différence avec l'informatique décisionnelle et concernant les données et leur utilisation:
                  
                  
                     <p>
                        Informatique décisionnelle : utilisation de statistique descriptive, sur des données à forte densité en information afin de mesurer des phénomènes, détecter des tendances… ;
                     </p>
                        
                     
                     <p>
                        Big data : utilisation de statistique inférentielle, sur des données à faible densité en information dont le grand volume permet d’inférer des corrélations et lois mathématiques ou statistiques (régressions…) donnant dès lors au big data (avec les limites de l’inférence) des capacités de généralisation pouvant être qualifiées de prédictives.
                     </p>
                     <p>Synthétiquement :</p>
                     <p>
                        l'informatique traditionnelle, informatique décisionnelle comprise, est basée sur un modèle du monde ;
                     </p>
                     <p>le big data vise à ce que les mathématiques trouvent un modèle dans les données.</p>
                  
                     
                  </p>

                  
            </p>
         </div>

      </div>
      </div>

      
    </div>
  </section>
  <section class="s1">
   <div class='main-container'>
    <h3 style="text-align: center;">Quelques Articles </h3>
     
    <div class="post-wrapper">

     <div>
       <div class="post">
         <img class="thumbnail" src="images/000000077628.jpg" alt="">
         <div class="post-preview">
           <h6 class="post-tittle">Face à la crise, les DSI français ont investi dans l'analytique</h6>
           <p class="post-intro"> <a href="https://www.lemondeinformatique.fr/actualites/lire-face-a-la-crise-les-dsi-francais-ont-investi-dans-l-analytique-82290.html" target="_blank">lien</a></p>
         </div>
       </div>
     </div>

     <div>  
       <div class="post">
         <img class="thumbnail" src="images/000000077332.jpg" alt="">
         <div class="post-preview">
           <h6 class="post-tittle">Amazon et le MIT lancent un concours pour optimiser les livraisons</h6>
           <p class="post-intro"> <a href="https://www.lemondeinformatique.fr/actualites/lire-amazon-et-le-mit-lancent-un-concours-pour-optimiser-les-livraisons-82103.html" target="_blank">lien</a></p>
         </div>
       </div>
     </div>

     <div>
       <div class="post">
         <img class="thumbnail" src="images/000000077263.png" alt="">
         <div class="post-preview">
           <h6 class="post-tittle">IoT et IA pour mieux suivre la production des guitares Fender</h6>
           <p class="post-intro"><a href="https://www.lemondeinformatique.fr/actualites/lire-iot-et-ia-pour-mieux-suivre-la-production-des-guitares-fender-82065.html" target="_blank">lien</a></p>
         </div>
       </div>
     </div>
      
     <div>
       <div class="post">
         <img class="thumbnail" src="images/data-scientist-data-donnees.jpeg" alt="">
         <div class="post-preview">
           <h6 class="post-tittle">Data et IA : la moitié des entreprises exploite moins de 25% de la donnée collectée et analysée</h6>
           <p class="post-intro"> <a href="https://www.usine-digitale.fr/article/data-et-ia-la-moitie-des-entreprises-exploite-moins-de-25-de-la-donnee-collectee-et-analysee.N756829" target="_blank">lien</a></p>
         </div>
       </div>
     </div>
      
      <div>
       <div class="post">
         <img class="thumbnail" src="images/3b115a3_qcE8OCodHbEoIDSXg4BJaEpV.jpg" alt="">
         <div class="post-preview">
           <h6 class="post-tittle">Le big data bouleverse la prédiction économique</h6>
           <p class="post-intro"> <a href="https://www.lemonde.fr/economie/article/2019/09/18/le-big-data-bouleverse-la-prediction-economique_5511835_3234.html" target="_blank">lien</a></p>
         </div>
       </div>
     </div>

   </div>

   </div>
 </section>

 
 

  <script type="text/javascript" src="script.js"></script>
</body>
</html>